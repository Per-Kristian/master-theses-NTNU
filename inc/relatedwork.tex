\chapter{Related work}
\label{chap:related}
This chapter aims to describe the literature relevant to the project.
In order to discuss the available literature, a few concepts from the field of biometrics must first be explained.
In order to compare the current user's characteristics to those of the genuine user, a \textit{reference} and a \textit{probe} is needed.
In the context of dynamic authentication and keystroke dynamics, the reference is a stored template of the genuine user's typing behavior recorded during the enrollment phase. 
This is the period where the biometric system learns the genuine user's characteristics.
The probe is a template of the current user's behavior, based on the keystrokes recorded during the user session.
Both of these templates are generated by extracting \textit{features} from the recorded keystrokes.

As mentioned in \Cref{sec:topic}, we will be focusing on the timing information of key actions.
The available \textit{timing feature} from a single keystroke is its \textit{duration}, which is a measurement of how long the key is held down.
Consecutive keystrokes are called \textit{n}-graphs, where \textit{n} is the number of keystrokes.
Single keystrokes can similarly be referred to as \textit{monographs}.
Features can also be extracted from these by measuring the \textit{latency} from the press/release of one key to another.
Using digraphs (or 2-graphs) as an example, the available latencies are as follows \cite{mondal}:
\begin{itemize}
    \item Press-Press(PP): The time elapsed from pressing down the first key to pressing the second key.
    \item Release-Release(RR): The time between releasing the first key and releasing the second key.
    \item Release-Press(RP): The time between releasing the first key and pressing the second key. This is often called \textit{flight time}.
    \item Press-Release(PR): The time from pressing the first key and releasing the second key.
\end{itemize}
In the following chapters, the term \textit{duration} will refer to the timing of a monograph, while \textit{latency} will be a general reference to timings of consecutive keystrokes, unless further specified by using the above acronyms.

With these concepts now explained, the related literature can be presented.
The CA system we will be extending is first summarized in \Cref{sec:related-CA} in order to allow for further discussions on what PA techniques may result in a good fit for our project.
Relevant PA systems are then discussed in \Cref{sec:related-other} with focus on classification methods, before a quick overview of other important aspects of the literature is given in \Cref{sec:related-overview}.

\section{Continuous authentication}
\label{sec:related-CA}
The CA system to be extended was a part of the doctoral thesis of Soumik Mondal \cite{mondal}, where a \textit{trust model} was used to lock imposters out.
Similarly to Bours' CA study \cite{BOURS201236}, Mondal's trust model worked by comparing monographs and digraphs (two consecutive keystrokes) to the genuine user's reference and having the result impact the current \textit{trust level} by means of a penalty-and-reward system.

After the initial static authentication, the user's trust level was set to 100, being the highest achievable level.
Probe typing patterns deviating from the reference would cause penalties in the form of lowering the trust level, while probe patterns complying with the reference would cause rewards to be given in the form of increasing the trust of the user's genuineness.
A \textit{lockout threshold} was set to a value below 100, and should the current user's trust level fall below said threshold, they would be locked out.
Ideal results would have had genuine users' trust levels never dropping below the threshold, while all imposters' levels would drop below the threshold after a small amount of actions performed.

An important part of the trust model was to determine how big a reward or penalty should be given per action performed.
For CA based on keystroke dynamics alone, Mondal \cite{mondal} presented and used an implementation of a trust model referred to as \textit{Dynamic Trust Model (DTM)}.
The size of the reward or penalty was determined by a single continuous function based on a \textit{classification score} computed by comparing the probe to the reference.
The larger the difference between the classification score and comparison threshold (not to be confused with the lockout threshold), the larger the penalty or reward became.
Therefore, an action with a classification score just below the comparison threshold would only result in a small decrease in trust level.

For keystroke action classification, Mondal followed a machine learning approach and two statistical approaches.
The first statistical approach (SA-1) calculated the classification score to be used in the DTM by using Scaled Euclidean Distance (SED) for monographs and a combination of SED and Correlation Distance for digraphs. 
The second statistical approach (SA-2) used the same distance metrics, but converted the distances into the classification score using fuzzy logic.
It is also worth mentioning that Bours used Scaled Manhattan Distance in his CA research \cite{BOURS201236}.
In Mondal's \cite{mondal} machine learning approach, an \textit{Artificial Neural Network}, a \textit{Counter-Propagation Artificial Neural Network} and a \textit{Support Vector Machine} were combined in a \textit{Multi-Classifier Fusion} architecture. 

The overall best machine learning results were achieved by training the classifier with data from the genuine user and from a set of imposter users, which in the original study \cite{mondal} was called Verification Process 3 (VP-3).
Testing was done with data from the genuine user which was not used for training and with data from the remaining imposters not involved in training.
This scenario is applicable in many cases, including the use on personal computers, as it shows the performance when imposters are not other users of the same system.
%The CA system to be extended \cite{mondal} has an Average Number of Imposter Actions (ANIA) rate of 499, meaning that it manages to detect imposters after 499 keystroke actions on average. 
%Furthermore it has an Average Number of Genuine Actions (ANGA) rate of 16057, which means that the genuine user can perform 16057 keystroke actions on average before the system mistakes them for being an imposter.
The performance was measured in terms of \textit{Average Number of Imposter Actions (ANIA)} and \textit{Average Number of Genuine Actions (ANGA)}, as well as number of imposters going undetected.
The ANIA rate represents the number of keystroke actions needed on average before imposters are detected, while the ANGA rate tells how many keystroke actions genuine users can perform on average before they are mistaken for being an imposter.

VP-3 achieved an ANGA rating of 16057 and an ANIA rating of 499, with 1.3\% of imposters not being detected.
When compared to the best statistical approach (SA-1) having an ANGA rating of 14096 and ANIA rating of 686 with 0.9\% of imposters not detected, one could argue that the VP-3 machine learning approach performed better due to imposters being rejected faster on average, and the genuine user being rejected less often.
However, SA-1 catches a larger percentage of imposters than what VP-3 does, which certainly is an important result.
%   Therefore, we plan to implement both SA-1 and VP-3 in this project, as there are benefits to both.
%NOTE: Supervisor suggests removing this last sentence.

Mondal's dataset consisted of mouse and keystroke data collected from 53 participants who were either students or university staff.
The data was collected in a completely unconstrained manner by having the participants install a tool for logging keystrokes and mouse events on their own computers.
They were not given any specific task, ensuring that the collected data represented the participants' natural behavior.

%NOTE: Mention publicly open datasets?
This dataset will be used for testing the CA and PA combination, although the recorded mouse activity will not be utilized as mouse dynamics is beyond the scope of the project.
Mondal reports that it has an average of 47600 keystroke events per participant. 
In his approach, he used 35\% of a user's recorded keystrokes for training, up to a maximum of 20000.
This is a sufficient amount of data seen in relation to the sizes of references used in state of the art PA studies.
Furthermore, 10\% was used for adjusting the parameters of the algorithms, and the rest was used for testing.
%We are likely to divide the dataset in a similar way to avoid distorting the performance in any direction. 
%NOTE: Supervisor suggests removing this last sentence.

%An average of 700 000 events were provided per participant, of which an average of $12.4\%$ ($\pm7.7\%$) are keystroke events.
%That leaves us with an average of 86800 ($\pm53900$) keystroke events to use for testing, 

\section{Periodic authentication}
\label{sec:related-other}
There is a significant amount of available literature on PA systems.
Discussing it all is beyond the scope of this project plan. The focus will therefore mostly be on research achieving viable results using free-text authentication and having potential for being incorporated into the CA system.
This section will present the various options available to us from literature regarding methods used for PA.
The PA system we will incorporate into the CA system is likely to consist of a custom combination of methods from existing research, as opposed to using an entire PA system as it is described by its original authors.

Periodic \textit{identification} systems are also included in this section.
These systems attempt to recognize who the user is without them claiming an identity first.
While generally having more computationally expensive matching algorithms than authentication systems, they may still have other relevant properties such as feature comparison methods which can also be used for authentication.

The literature discussed in this section usually refer to their own solutions as CA, however we will refer to them as PA if they are not truly continuous due to the reason stated in \Cref{sec:topic}.
An extensive and detailed literature study of PA systems \cite{nilsenSpec} was delivered in IMT4215 Specialization Project in December 2017.
This section further builds upon the knowledge collected in said study.

\subsection{Statistical approaches}
To the best of our knowledge, incorporating a PA system into a CA system has not been done before. 
We can therefore not know the answers to our research question and subquestions before performing our own analysis of the CA/PA combination.
However, we can look at what promising results have been achieved, and how they were achieved.
This will give us indicators for how we can assemble the best combination of CA and PA.

One of the most cited articles on PA systems was written by Gunetti and Picardi \cite{gnp} and published in 2005.
They introduced the 'A' and 'R' distances, which were absolute and relative distances used for classification, and they used 2-, 3- and 4-graph latencies in their distance calculations.
Their solution is interesting due to how it accounts for variation in genuine users' typing behavior.
If a genuine user for some reason types slower than usual, for instance due to cold fingers, their typing pattern is likely to stay relatively similar to the regular pattern, only at a slower speed.
The relative distance accounts for this when comparing a probe to a reference, and is used in combination with the absolute distances of speed between the samples.
They achieved a False Match Rate (FMR) of 0.005\% and False Non-Match Rate (FNMR) of 4.833\%, meaning imposters were undetected in 0.005\% of verification processes, while genuine users were wrongfully believed to be imposters in 4.833\% of all cases. 
This was using a \textit{block size} of 700-900 keystrokes, meaning 700-900 recorded keystrokes were used to form each probe.
Block sizes this large give imposters a fairly large window of unauthorized access, and for the CA/PA combination, we would like a block size similar to the original CA system's ANIA rate, or smaller.
This is more easily expressed by converting the FMR and FNMR rates into respective ANIA and ANGA rates by means of the formulas presented in \cite{CA-performance}, where Bours and Mondal first introduced the ANIA and ANGA rates.
A middleground block size of 800 keystrokes will be used for simplicity's sake:

\begin{equation}
ANIA = \frac{block size}{(1-FMR)} = \frac{800}{(1-0.00005)} \approx 800
\end{equation}

\begin{equation}
ANGA = \frac{block size}{FNMR} = \frac{800}{0.04833} \approx 16553
\end{equation}

Genuine users are rarely rejected with this ANGA rate, which is also the case in Mondal's \cite{mondal} CA system.
However, the ANIA rate is higher than that of the original CA system which was 499.
We would prefer a lower ANIA rate than 800 so that the PA system will in more cases have a chance to make a decision before the CA system has already removed access from the current user.
This way we can make more use of both authentication systems, which will hopefully impact our \textit{research sub-question 1} regarding detection performance.

Apart from accuracy, we must also take computational performance into account to discuss \textit{research sub-question 2}.
Gunetti and Picardi's \cite{gnp} system used 140 seconds per authentication, which was a clear issue.
Granted, this was on a Pentium 4 processor, and more modern CPUs should provide significantly better performance.
The reason for the suffering computational performance was a sub-optimal classification algorithm which compared a probe sample to every single legal user's reference in the system, which in their experiment was 40 users.
This is useful for periodic \textit{identification}, where the system attempts to recognize who the user is without them claiming an identity first.
We would prefer to avoid using such an algorithm in our project in order to keep processing costs at a minimum.
Simply modifying the algorithm to not consider all users per verification process could be an option for increasing the speed, however we can not predict the impact that would have on the detection performance.
%For 

Several other researchers have also used Gunetti and Picardi's A and/or R distances \cite{davoudi2009, davoudi2010, superResults, hu, sliding, Kolakowska2011, Messerman, Pinto2014, meaningless, KANG201572}.
%NOTE INCLUDE SOME OF THESE IN SPEC PROJ?
Of these, especially Ferreira and Santos \cite{superResults} stand out as they attempted to tackle both the block size and computational performance problems of Gunetti and Picardi's \cite{gnp} study.
They used a block size of 250 keystrokes, achieving an Equal Error Rate (EER) of 1.4\%, meaning the FMR and FNMR are equal at that percentage.
They also mentioned that a specific setting gave a result of 0.5\% FMR and 2.7\% FNMR, which corresponds to an ANIA of 251 and an ANGA of 9259.
Considering the CA system's ANIA is 499, this amount of keystrokes may positively impact the CA system's imposter detection rate.
The PA system's ANGA is also in an acceptable range which should not lead to very many false rejections per day.

As opposed to Gunetti and Picardi's solution, Ferreria and Santos' system only compared probes to the reference of the claimed identity, assuring fast computation.
The size of the reference used was 11250 keystrokes, which is comparable to Mondal's training sets, as mentioned in \cref{sec:related-CA}.
Their method involved extracting monograph durations and digraph RP-times.
%Flight time is a commonly used term for the latency between the release of one key to the pressing of the next.
Furthermore they also used PP-latencies of 2-, 3-, and 4-graphs, similarly to Gunetti and Picardi \cite{gnp}.

An important aspect of their system was to identify the 10\% most consistent n-graphs with regards to extracted features.
In other words, these were the n-graphs which the user would type in a similar manner most of the time.
Then, during a verification process, the system would place more strict expectations onto these n-graphs when they were typed by the current user.
All in all, this PA system consisted of several mechanisms which could be useful for our project, as it provided solutions to the block size and computational performance issues in Gunetti and Picardi's \cite{gnp} system.
They also performed their experiments on data collected in an unconstrained manner, which matches the setting used in Mondal's \cite{mondal} dataset. 
This increases the possibility of achieving similar performance in our implementation.

Other statistical methods than the A and R measures have also been used in literature.
Regarding both CA and PA systems, examples include Correlation distance \cite{mondal}, Euclidean distance \cite{Kaneko, Monrose, Harun, Tappert}, Scaled Euclidean distance \cite{mondal}, Kolmogorov-Smirnov Test \cite{park, KANG201572}, multivariate testing \cite{KANG201572}, Chi-square test \cite{chi-square}, Manhattan distance \cite{Kaneko, Harun, cognition} and Scaled Manhattan distance \cite{BOURS201236, Harun}.
%NOTE FIX FÃ˜RSTE SETNING UNDER HER.
Some studies have applied several classifiers \cite{hu, mondal, KANG201572, Harun, cognition, Kaneko}. 
For instance, Kaneko et al. \cite{Kaneko} applied Euclidean distance, Manhattan distance, a proposed custom distance and Gaussian probability density function. Results showed that Euclidean distance performed best, however the experiment setting was writing a fixed Japanese text of around 200 keystrokes.
It is hard to know whether the results would be similar for the dataset to be used in our project, due to the large differences in data collection methods.
%This is one of many examples showing the difficulty of directly comparing studies in this field.
%NOTE: Kolakowska not present in specialization project?

\subsection{Machine learning approaches}
Machine learning has also been utilized in recent years, with some of the research presenting promising results.
An interesting example of this is Ahmed and Traore's \cite{Ahmed} work from 2007, who used neural networks for classification.
Their system uses neural networks combined with a key mapping technique in order to predict digraphs missing from a user's reference.
This means that a much smaller amount of different digraphs need to be recorded in the enrollment phase.
If the current user types a digraph to be used for authentication which was never recorded for the reference, it can still be compared to the \textit{approximated} values of the missing digraphs, based on the genuine user's actual recorded digraphs.
They achieved an FMR of 0.0152\% and FNMR of 4.82\% with a block size of 500 keystrokes and considering monograph durations and digraph RP-latency.
As this can be converted to an ANIA of 500 and ANGA of 10373, it could fit the CA system as it's ANIA of 499 is an \textit{average}, and can therefore be much higher in some cases.
In those cases, a block size of 500 would be small enough to trigger an authentication faster than the CA system could lock the user out.
They also state that their system is much faster than Gunetti and Picardi's system, which further supports our \textit{research sub-question 2}.

In addition to neural networks being used in literature \cite{Ahmed, Harun, mondal},
other machine learning methods have also been used in CA and PA systems, such as k-means clustering \cite{KIM2017, Solami}, kernel ridge regression \cite{900words}, decision trees \cite{alsultan} random forest \cite{fast} and k-nearest neighbor \cite{hu, monaco, KANG201572, stewart, Tappert}.
Support vector machine was also used in Mondal's \cite{mondal} CA system along with neural networks, as mentioned in \Cref{sec:related-CA}.


%"FAST" Shim uses random forest. Good results but hard to apply in practice according to \cite{KANG201572}
%NOTE: MENTION RESEARCH QUESTION 1.c.

\section{Overview}
\label{sec:related-overview}
The previous section described the methods used in literature as well as highlighting some particularly interesting studies.
Since we are not restricted to using the entire systems as they are described by their authors, it can be beneficial to look at a general overview of the literature, and compare certain properties of the studies.

\subsection{Data collection}
\label{sec:related-overview-collection}
The approaches used for experimental data collection is interesting for the project, as some are more similar to Mondal's \cite{mondal} unconstrained collection approach than others.
There are several other studies with unconstrained data collection \cite{Ahmed, BOURS201236, superResults, sliding, Janakiraman2007,  Pinto2014, chi-square, dowl, occ}, whereas some studies constrained the participants to typing freely into a textbox such as in a webform \cite{davoudi2009, davoudi2010, gnp, Solami, KANG201572, markov, meaningless}.
Other studies had the participants perform specific tasks \cite{monaco, Monrose,  park, 900words}, such as writing a long fictional text.
Participants wrote static text in \cite{hu, Kolakowska2011}, and manually copied various texts in \cite{meaningless, alsultan, KIM2017}.
%while Kim et al. \cite{KIM2017} assigned different such texts to every participants to simulate free-text.
While the focus of our project is on keystrokes from physical keyboards, it is worth mentioning that keystroke dynamics using soft or touch keyboards has also been researched, such as is Kang and Cho's publication from 2015 \cite{KANG201572}.

With regards to participants included in experiments, 14 researches had 30 or more participants \cite{Messerman, gnp, Ahmed, superResults, KIM2017, 900words, sliding, Monrose, park, monaco, KANG201572, dowl, cognition, meaningless, stewart}.
One of these had 2000 participants \cite{900words}.
Since the dataset we will be using \cite{mondal} contains data from 53 users, the variance in inter-user behavior is expected to be more than high enough to be comparable to other studies.

\subsection{Feature extraction}
Looking at how feature extraction is performed is also of value, in order to see viable approaches we can use.
The related studies extracted various latencies from n-graphs, however some also consider monograph durations \cite{Pinto2014, superResults, KIM2017, Ahmed, Monrose, Janakiraman2007, monaco, BOURS201236, chi-square, Kolakowska2011, cognition, stewart, Tappert, pohmm}, which Mondal's \cite{mondal} CA system also does.
When considering consecutive keystrokes, some studies \cite{davoudi2009, davoudi2010, KIM2017, Ahmed, Janakiraman2007, Solami, BOURS201236, Monrose, park, monaco, chi-square, markov, Harun, occ, stewart, Tappert, meaningless, fast, pohmm} restricted themselves to considering digraphs only.
This was also done by Mondal \cite{mondal}.
One study \cite{900words} used only trigraphs, while the rest used several types of n-graphs.
Locklear et al. \cite{cognition} used congition-centric features in addition to keystroke timings,
and six studies \cite{occ, Tappert, stewart, alsultan, monaco, pohmm} included other statistical features such as the rate of certain key presses, words per minute and/or rate of typing errors.
Of these, one of the studies \cite{stewart} presented an  extension of an existing system \cite{Tappert} where the new system also utilized stylometry.

Block size in periodic systems is also relevant to look at, as a small block size is ideal for the CA/PA combination.
Ten studies used a block size of 500 keystrokes or less \cite{superResults, Messerman, Pinto2014, Ahmed, hu, park, Janakiraman2007, chi-square, markov, Harun, fast}.
Studies achieving good performance using such a small amount of keystrokes are important to consider when we are to implement the PA part of the project.
However, more factors must also be taken into consideration. 
For example, one of the studies \cite{chi-square} tested the performance of their system using test data that was already included in the users' references, which artificially skews the results in a positive direction.
Another example is one of the studies with a small block size using static text instead of free-text \cite{hu}.
Therefore, this chapter is concluded with \Cref{tab:summary}, where an overview of the properties of the related studies can be found.


\begin{table}[ht]
\centering
\resizebox*{\dimexpr\textheight-12\baselineskip\relax}{!}{%
\begin{tabular}{llllllll}
\hline
\textbf{Paper} & \textbf{Block length} & \textbf{Users} & \textbf{Task} & \textbf{Method} & \textbf{Performance} & \textbf{Features} & \textbf{DB} \\ \hline
\cite{gnp} & 700-900 & 40 & Webform & R and A measures & \begin{tabular}[c]{@{}l@{}}FMR 0.005\% \\ FNMR 4.833\%\end{tabular} & \begin{tabular}[c]{@{}l@{}}2-, 3- and \\ 4-graph latency\end{tabular} & Own* \\ \hline
\cite{Messerman} & 50 - 150 & 50 & E-mail & R measure & \begin{tabular}[c]{@{}l@{}}FMR 2.02\%\\ FNMR 1.84\%\end{tabular} & n-graph latency & Own \\ \hline
\cite{superResults} & 250 & 60 & Unconstrained & R and A measures & EER 1.4\% & \begin{tabular}[c]{@{}l@{}}Duration, Digraph RP,\\ PP for \{1-4\}-graphs\end{tabular} & Own \\ \hline
\cite{Pinto2014} & 150 & 10 & Unconstrained & R and A measures & \begin{tabular}[c]{@{}l@{}}FMR $\sim$2\%\\ FNMR $\sim$2\%\end{tabular} & \begin{tabular}[c]{@{}l@{}}Duration, Digraph RP,\\ PP for \{1-4\}-graphs\end{tabular} & Own \\ \hline
\cite{davoudi2009} & 700-900 & 21 & Webform & Modified R measure & \begin{tabular}[c]{@{}l@{}}FMR 0.08\%\\ FNMR 18.8\%\end{tabular} & Digraph latency & \cite{gnp} \\ \hline
\cite{davoudi2010} & 700-900 & 21 & Webform & Weighted R measure & \begin{tabular}[c]{@{}l@{}}FMR 0.07\%\\ FNMR 15.2\%\end{tabular} & Digraph latency & \cite{gnp} \\ \hline
\cite{Ahmed} & 500 & 53 & Unconstrained & Neural Network (NN) & \begin{tabular}[c]{@{}l@{}}FMR 0.0152\%\\ FNMR 4.82\%\\ EER 2.13\%\end{tabular} & \begin{tabular}[c]{@{}l@{}}Duration, \\ digraph latency 
%flight time
\end{tabular} & Own \\ \hline
\cite{hu} & 36 & 19 & Webform, static text & \begin{tabular}[c]{@{}l@{}}R and A measures,\\ k-Nearest Neighbor\end{tabular} & \begin{tabular}[c]{@{}l@{}}FMR 0.045\%\\ FNMR 0.005\%\end{tabular} & n-graph latency & Own \\ \hline
\cite{900words} & 900 words & 2000 & Pre-defined tasks & \begin{tabular}[c]{@{}l@{}}Kernel Ridge Regression,\\ truncated RBF kernel\end{tabular} & EER 1.39\% & Trigraph latency & \cite{chang} \\ \hline
\cite{KIM2017} & 1000 & 150 & Copytask & K-means clustering & EER 0.44\% & \begin{tabular}[c]{@{}l@{}}Duration,\\ digraph latencies\end{tabular} & Own \\ \hline
\cite{Solami} & 700-900 & 14 & Webform & K-means clustering & Accuracy 100\% & Digraph latency & \cite{gnp} \\ \hline
\cite{Janakiraman2007} & Minimum 2 & 22 & Unconstrained & Bhattacharyya distance & Accuracy 70-100\% & \begin{tabular}[c]{@{}l@{}}Duration,\\ digraph latency
%flight time
\end{tabular} & Own \\ \hline
\cite{Monrose} & Unknown & 31 & Pre-defined tasks & \begin{tabular}[c]{@{}l@{}}Euclidean distance, \\ weighted probability\end{tabular} & Accuracy 23\% & \begin{tabular}[c]{@{}l@{}}Duration,\\ digraph latency
%flight time
\end{tabular} & Own \\ \hline
\cite{sliding} & \begin{tabular}[c]{@{}l@{}}1 min\\ sliding window\end{tabular} & 56 & Unconstrained & R and A measures & \begin{tabular}[c]{@{}l@{}}FMR 1\%\\ FNMR 11.5\%\end{tabular} & n-graph latency & Own* \\ \hline
\cite{BOURS201236} & Continuous & 25 & Unconstrained & Scaled Manhattan distance & ANIA 182 & \begin{tabular}[c]{@{}l@{}}Duration,\\ digraph latency\end{tabular} & Own \\ \hline
\cite{mondal} & Continuous & 53 & Unconstrained & \begin{tabular}[c]{@{}l@{}}Scaled Euclidean Distance,\\ Correlation distance, NN,\\ Support Vector Machine\end{tabular} & \begin{tabular}[c]{@{}l@{}}ANIA 499\\ ANGA 16057\end{tabular} & \begin{tabular}[c]{@{}l@{}}Duration,\\ digraph latencies\end{tabular} & Own \\ \hline
\cite{monaco} & 775 on average & 119 & Pre-defined tasks & k-Nearest Neighbor & EER 3.7\% & \begin{tabular}[c]{@{}l@{}}Duration,\\ digraph latencies,\\ statistical features\end{tabular} & Own \\ \hline
\cite{park} & 300 & 35 & Pre-defined tasks & Kolmogorov-smirnov test & EER 0.09\% & Digraph latency & Own \\ \hline
\cite{chi-square} & 150 & 26 & Unconstrained & Chi-square test & FNMR 5\% & \begin{tabular}[c]{@{}l@{}}Duration,\\ digraph latency\end{tabular} & Own \\ \hline
\cite{Kolakowska2011} & 600 & 10 & Webform, static text & R and A measures & \begin{tabular}[c]{@{}l@{}}FMR 4.09\%\\ FNMR 5.17\%\end{tabular} & \begin{tabular}[c]{@{}l@{}}Duration; \\ 2-, 3-, 4- and\\ 5-graph latency\end{tabular} & Own \\ \hline
\cite{KANG201572} & 100-1000 & 35 & Textbox & 12 different classifiers & EER 5.64-14.53\% & Digraph latency %(PP) 
& Own \\ \hline
\cite{dowl} & Continuous & 35 & Unconstrained & Unknown distance & \begin{tabular}[c]{@{}l@{}}ANIA 6390\\ ANGA 68755\end{tabular} & \begin{tabular}[c]{@{}l@{}}Digraph, trigraph and\\ word latency\end{tabular} & Own \\ \hline
\cite{markov} & 110 & 15 & Textbox & Markov chain & EER 12.7\% & Digraph latency %(PP)
& Own \\ \hline
\cite{Harun} & 110 & 15 & Textbox & NN and 5 distances & EER 22.9\% & Digraph latency %(PP)
& \cite{markov} \\ \hline
\cite{cognition} & \begin{tabular}[c]{@{}l@{}}Time based\\ blocks of \\ diff. lengths.\end{tabular} & 486 & Pre-defined tasks & \begin{tabular}[c]{@{}l@{}}Manhattan distance,\\ Fisher score\end{tabular} & EER 4.55-13.37\% & \begin{tabular}[c]{@{}l@{}}Duration, digraph \\ latency, cognition-\\ centric features\end{tabular} & Own \\ \hline
\cite{occ} & Minimum 500 & 10 & E-mail & Custom one-class classifier & \begin{tabular}[c]{@{}l@{}}FMR 4.13\%\\ FNMR 12.39\%\end{tabular} & \begin{tabular}[c]{@{}l@{}}Statistical features\\ incl. digraph latencies\end{tabular} & Own \\ \hline
\cite{meaningless} & $\sim$850-1800 & 50 & \begin{tabular}[c]{@{}l@{}}Textbox; copytask\\ and free text\end{tabular} & \begin{tabular}[c]{@{}l@{}}R and Similarity \\ measures\end{tabular} & EER 10-15\% & Digraph latency %(PP)
& Own \\ \hline
\cite{stewart} & $\sim$3000-6000 & 30 & \begin{tabular}[c]{@{}l@{}}Electronic \\ university exam\end{tabular} & k-Nearest Neighbor & EER 0.55-1.4\% & \begin{tabular}[c]{@{}l@{}}Digraph latencies,\\ stylometry.\end{tabular} & Own \\ \hline
\cite{fast} & 250 & 21 & Webform & Clustering, random forest & \begin{tabular}[c]{@{}l@{}}FMR 3.47\%\\ FNMR 0\%\end{tabular} & Digraph latency %(PP) & 
& \cite{gnp} \\ \hline
\cite{alsultan} & 1000 & 30 & Textbox; copytask & Decision trees & \begin{tabular}[c]{@{}l@{}}FMR 1.1\%\\ FNMR 28\%\end{tabular} & Statistical features & Own \\ \hline
\cite{pohmm} & \begin{tabular}[c]{@{}l@{}}Sliding window\\ of length 500\end{tabular} & 55 & Pre-defined tasks & \begin{tabular}[c]{@{}l@{}}Partially Observable\\ Hidden Markov Model\end{tabular} & ANIA 55.18 & \begin{tabular}[c]{@{}l@{}}Duration,\\ digraph latencies,\\ statistical features\end{tabular} & \cite{essay}

%\textbf{Paper}  & \textbf{Block length}                                          & \textbf{Users} & \textbf{Task}        & \textbf{Method}                                                                                                         & \textbf{Performance}                                                            & \textbf{Features}                                                                          & \textbf{DB} \\ \hline
%gnp             & 700-900                                                        & 40             & Webform              & R and A measures                                                                                                        & \begin{tabular}[c]{@{}l@{}}FMR 0.005\% \\ FNMR 4.833\%\end{tabular}             & \begin{tabular}[c]{@{}l@{}}2-, 3- and \\ 4-graph latency\end{tabular}                      & Own*        \\ \hline
%Messerman       & 50 - 150                                                       & 50             & Webmail              & R measure                                                                                                               & \begin{tabular}[c]{@{}l@{}}FMR 2.02\%\\ FNMR 1.84\%\end{tabular}                & n-graph latency                                                                            & Own         \\ \hline
%superResults    & 250                                                            & 60             & Unconstrained        & R and A measures                                                                                                        & EER 1.4\%                                                                       & \begin{tabular}[c]{@{}l@{}}Dwell time, flight time\\ for 2-, 3-, and 4-graphs\end{tabular} & Own         \\ \hline
%Pinto2014       & 150                                                            & 10             & Unconstrained        & R and A measures                                                                                                        & \begin{tabular}[c]{@{}l@{}}FMR $\sim$2\%\\ FNMR $\sim$2\%\end{tabular}          & \begin{tabular}[c]{@{}l@{}}Dwell time, flight time\\ for 2-, 3-, and 4-graphs\end{tabular} & Own         \\ \hline
%davoudi2009     & 700-900                                                        & 21             & Webform              & Modified R measure                                                                                                      & \begin{tabular}[c]{@{}l@{}}FMR 0.08\%\\ FNMR 18.8\%\end{tabular}                & Digraph latency                                                                            & gnp         \\ \hline
%davoudi2010     & 700-900                                                        & 21             & Webform              & Weighted R measure                                                                                                      & \begin{tabular}[c]{@{}l@{}}FMR 0.07\%\\ FNMR 15.2\%\end{tabular}                & Digraph latency                                                                            & gnp         \\ \hline
%Ahmed           & 500                                                            & 53             & Unconstrained        & Neural Networks (NN)                                                                                                    & \begin{tabular}[c]{@{}l@{}}FMR 0.0152\%\\ FNMR 4.82\%\\ EER 2.13\%\end{tabular} & \begin{tabular}[c]{@{}l@{}}Dwell time, \\ digraph flight time\end{tabular}                 & Own         \\ \hline
%hu              & 36                                                             & 19             & Webform, static text & \begin{tabular}[c]{@{}l@{}}R and A measures,\\ k-Nearest Neighbor\end{tabular}                                          & \begin{tabular}[c]{@{}l@{}}FMR 0.045\%\\ FNMR 0.005\%\end{tabular}              & n-graph latency                                                                            & Own         \\ \hline
%900words        & 900 words                                                      & 2000           & Pre-defined tasks    & \begin{tabular}[c]{@{}l@{}}Kernel Ridge Regression,\\ truncated RBF kernel\end{tabular}                                 & EER 1.39\%                                                                      & Trigraph flight times                                                                      & chang       \\ \hline
%KIM2017         & 1000                                                           & 150            & Pre-defined task     & K-means clustering                                                                                                      & EER 0.44\%                                                                      & \begin{tabular}[c]{@{}l@{}}Dwell time,\\ digraph latencies\end{tabular}                    & Own         \\ \hline
%Solami          & 700-900                                                        & 14             & Webform              & K-means clustering                                                                                                      & Accuracy 100\%                                                                  & Digraph latency                                                                            & gnp         \\ \hline
%Janakiraman2007 & Minimum 2                                                      & 22             & Unconstrained        & Bhattacharyya distance                                                                                                  & Accuracy 70-100\%                                                               & \begin{tabular}[c]{@{}l@{}}Dwell time,\\ digraph flight time\end{tabular}                  & Own         \\ \hline
%Monrose         & Unknown                                                        & 31             & Pre-defined tasks    & \begin{tabular}[c]{@{}l@{}}Euclidean distance, \\ weighted probability\end{tabular}                                     & Accuracy 23\%                                                                   & \begin{tabular}[c]{@{}l@{}}Dwell time,\\ digraph flight time\end{tabular}                  & Own         \\ \hline
%sliding         & \begin{tabular}[c]{@{}l@{}}1 min\\ sliding window\end{tabular} & 56             & Unconstrained        & R and A measures                                                                                                        & \begin{tabular}[c]{@{}l@{}}FMR 1\%\\ FNMR 11.5\%\end{tabular}                   & n-graph latency                                                                            & Own*        \\ \hline
%BOURS201236     & Continuous                                                     & 25             & Unconstrained        & Scaled Manhattan distance                                                                                               & 182 ANIA                                                                        & \begin{tabular}[c]{@{}l@{}}Dwell time,\\ digraph latency\end{tabular}                      & Own         \\ \hline
%mondal          & Continuous                                                     & 53             & Unconstrained        & \begin{tabular}[c]{@{}l@{}}Scaled Euclidean Distance,\\ Correlation distance, NN,\\ Support Vector Machine\end{tabular} & \begin{tabular}[c]{@{}l@{}}499 ANIA\\ 16057 ANGA\end{tabular}                   & \begin{tabular}[c]{@{}l@{}}Dwell time,\\ digraph latencies\end{tabular}                    & Own         \\ \hline
%monaco          & 775 on average                                                 & 119            & Pre-defined tasks    & k-Nearest Neighbor                                                                                                      & EER 3.7\%                                                                       & \begin{tabular}[c]{@{}l@{}}Dwell time,\\ digraph latencies\end{tabular}                    & Own         \\ \hline
%park            & 300                                                            & 35             & Pre-defined tasks    & Kolmogorov-smirnov test                                                                                                 & EER 0.09\%                                                                      & Digraph latency                                                                            & Own         \\ \hline
%chi-square      & 150                                                            & 26             & Unconstrained        & Chi-square test                                                                                                         & FNMR 5\%                                                                        & \begin{tabular}[c]{@{}l@{}}Dwell time,\\ digraph latency\end{tabular}                      & Own         \\ \hline
%Kolakowska2011  & 600                                                            & 10             & Webform, static text & R and A measures                                                                                                        & \begin{tabular}[c]{@{}l@{}}FMR 4.09\%\\ FNMR 5.17\%\end{tabular}                & \begin{tabular}[c]{@{}l@{}}Dwell time; \\ 2-, 3-, 4- and\\ 5-graph latency\end{tabular}    & Own         \\ \hline
%KANG201572      & 100-1000                                                       & 35             & Textbox              & 12 different classifiers                                                                                                & EER 5.64-14.53\%                                                                & Digraph latency (PP)                                                                       & Own         \\ \hline
%dowl            & Continuous                                                     & 35             & Unconstrained        & Unknown distance                                                                                                        & \begin{tabular}[c]{@{}l@{}}ANIA 6390\\ ANGA 68755\end{tabular}                  & \begin{tabular}[c]{@{}l@{}}Digraph, trigraph and\\ word latency\end{tabular}               & Own         \\ \hline
%markov          & 110                                                            & 15             & Textbox              & Markov chain                                                                                                            & EER 12.7\%                                                                        & Digraph latency (PP)                                                                       & Own*        \\ \hline
%Harun           & 110                                                            & 15             & Textbox              & NN and 5 distances                                                                                                      & EER 22.9\%                                                                      & Digraph latency (PP)                                                                       & markov      \\ \hline
%
%cognition       & \begin{tabular}[c]{@{}l@{}}Time based\\ blocks of \\ diff. lengths.\end{tabular} & 486            & Pre-defined tasks    & \begin{tabular}[c]{@{}l@{}}Manhattan distance,\\ Fisher score\end{tabular}                                              & EER 4.55-13.37\%                                                                & \begin{tabular}[c]{@{}l@{}}Dwell time, digraph \\ latency, cognition-\\ centric features\end{tabular} & Own         \\ \hline
%occ             & Minimum 500                                                                      & 10             & E-mail               & Custom one-class classifier                                                                                             & \begin{tabular}[c]{@{}l@{}}FMR 4.13\%\\ FNMR 12.39\%\end{tabular}               & \begin{tabular}[c]{@{}l@{}}Statistical features\\ including digraph lat.\end{tabular}                 & Own         \\ \hline
\end{tabular}
}
\caption{Summary of relevant periodic and continuous systems. Datasets marked with an ampersand (*) in the database (DB) column are available publicly or by request. This table is an extension of an earlier version in the author's IMT4215 Specialization Project report \cite{nilsenSpec}.}
\label{tab:summary}
\end{table}

%
%\begin{table}[ht]
%\resizebox{\textwidth}{!}{%
%\begin{tabular}{ |l|p{2.1cm}|l|p{2.15cm}|p{3cm}|p{2.3cm}|p{2.5cm}|l| } 
% \hline
% \bf Paper & \bf Block length & \bf Users & \bf Task & \bf Method & \bf Performance & \bf Feature & \bf DB \\ \hline
% \cite{gnp} & 700-900 & 40 & Webform & R and A measures & FMR 0.005\% FNMR 4.833\% & 2-, 3- and 4-graph latency & Own*\\ \hline
% \cite{Messerman} & 50 - 150 & 50 & Webmail & R measure & FMR 2.02\%  FNMR 1.84\% & n-graph latency & Own\\ \hline
% \cite{superResults} & 250 & 60 & Unconstrained & R and A measures & EER 1.4\% & Dwell time, flight time for 2-, 3-, and 4-graphs & Own\\ \hline
% \cite{Pinto2014} & 150 & 10 & Unconstrained & R and A measures & FMR ~2\% FNMR ~2\% & Dwell time, flight time for 2-, 3-, and 4-graphs & Own \\ \hline
% \cite{davoudi2009} & 700-900 & 21 & Webform & Modified R measure & FMR 0.08\% FNMR 18.8\% & Digraph latency & \cite{gnp} \\ \hline
% \cite{davoudi2010} & 700-900 & 21 & Webform & Weighted R measure & FMR 0.07\% FNMR 15.2\% & Digraph latency & \cite{gnp} \\ \hline
% %Singh &- & - & - & - & - & STATIC AUTHENT. DONT BOTHER & \\ \hline
% %Kaneko \cite{Kaneko} & ~200 & 51 & No & Euclidean & 0.66\% EER & Static fixed text, jap. & di \\ \hline
% \cite{Ahmed} & 500 & 53 & Unconstrained & Neural Networks (NN) & FMR 0.0152\%, FNMR 4.82\%, ERR 2.13\% & Dwell time, digraph flight time & Own\\\hline
% \cite{hu} & 36 & 19 & Webform, static text & R and A measures, k-Nearest Neighbor & FMR 0.045\% FNMR 0.005\% & n-graph latency & Own \\ \hline
% \cite{900words} & 900 words & 2000 & Pre-defined tasks & Kernel Ridge Regression, truncated-RBF kernel & EER 1.39\% & Trigraph flight times & \cite{chang} \\ \hline
% \cite{KIM2017} & 1000 & 150 & Pre-defined task & K-means clustering & EER 0.44\% & Dwell time, digraph latencies & Own \\ \hline
% %\cite{CPE3718} & 14 & 31 & Password & MLP Neural Network & EER 0.051\% & Static auth \\ \hline
% \cite{Solami} & 700-900 & 14 & Webform & K-means clustering & Accuracy 100\% & Digraph latency & \cite{gnp}\\ \hline
% \cite{Janakiraman2007} & Minimum 2 & 22 & Unconstrained & Bhattacharyya distance & Accuracy 70\%-100\% & Dwell time, digraph flight time & Own\\ \hline
% \cite{Monrose} & Unknown & 31 & Pre-defined tasks & Euclidean distance, weighted probability & Accuracy 23\% & Dwell time, digraph flight time & Own\\ \hline
% \cite{sliding} & 1 min sliding window & 56 & Unconstrained & R and A measures & FMR 1\% FNMR 11.5\% & n-graph latency & Own*\\ \hline
% \cite{BOURS201236} & Continuous & 25 & Unconstrained & Scaled Manhattan distance & 182 ANIA & Dwell time, digraph latency & Own\\ \hline
% \cite{mondal} & Continuous & 53 & Unconstrained & Scaled Euclidean distance, Correlation distance, NN, support vector machine & 499 ANIA, 16057 ANGA & Dwell time, digraph latencies & Own \\ \hline
% \cite{monaco} & 775 on average & 119 & Pre-defined tasks & k-Nearest Neighbor & EER 3.7\% & Dwell time, digraph latencies incl. flight time & Own \\ \hline
% \cite{park} & 300 & 35 & Pre-defined tasks & Kolmogorov-smirnov Test & EER 0.09\% & Digraph latency & Own \\ \hline
% \cite{chi-square} & 150 & 26 & Unconstrained & Chi-square test & FMR 0\%, FNMR 5\% & Dwell time, digraph latency & Own \\ \hline
% \cite{Kolakowska2011} & 600 & 10 & Webform, static text & R and A measures & FMR 4.09\%, FNMR 5.17\% & Dwell time; 2-, 3-, 4- and 5-graph latency & Own\\ \hline
% \cite{KANG201572} & 1000 & 35 & Textbox & 12 & & & \\ \hline 
%\end{tabular}
%}
%\caption{Summary of relevant periodic and continuous systems. Datasets marked with an ampersand (*) in the database (DB) column are available publicly or by request. This table is also included in the author's IMT4215 Specialization Project report \cite{nilsenSpec}.}
%\label{tab:summary}
%\end{table}